
 <!DOCTYPE HTML>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  
    <title>Jianyu</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="PengYuan">
    

    
    <meta property="og:type" content="website">
<meta property="og:title" content="Jianyu">
<meta property="og:url" content="https://pengyuanqiuqiu.github.io/index.html">
<meta property="og:site_name" content="Jianyu">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Jianyu">

    
    <link rel="alternative" href="http://www.163.com/rss/" title="Jianyu" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/jacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/jacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.png" alt="Jianyu" title="Jianyu"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="Jianyu">Jianyu</a></h1>
				<h2 class="blog-motto">Learn more and more</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" name="q" autocomplete="off" maxlength="20" placeholder="搜索" />
						<input type="hidden" name="q" value="site:pengyuanqiuqiu.github.io">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main">

   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/03/22/机器学习的降维为特征选择的区别/" title="特征选择和降维的区别" itemprop="url">特征选择和降维的区别</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="PengYuan" target="_blank" itemprop="author">PengYuan</a>
		
  <p class="article-time">
    <time datetime="2018-03-22T02:52:21.516Z" itemprop="datePublished"> 发表于 2018-03-22</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><p>原因：</p>
<p>在现实应用中，数据特征属性很多，存在一部分属性与结果并不相关；而且特征的维度太高导致训练模型时间较长，模型更加复杂，泛化能力较低。</p>
<p>方法：</p>
<h2 id="1、过滤式选择-（Filter）"><a href="#1、过滤式选择-（Filter）" class="headerlink" title="1、过滤式选择 （Filter）"></a>1、过滤式选择 （Filter）</h2><p> 其主要思想是：对每一维的特征“打分”，即给每一维的特征赋予权重，这样的权重就代表着该维特征的重要性，然后依据权重排序。</p>
<p>​    主要的方法有：</p>
<ul>
<li>卡方检验</li>
<li>互信息法</li>
<li>方差选择法</li>
</ul>
<h2 id="2、包裹式方法"><a href="#2、包裹式方法" class="headerlink" title="2、包裹式方法"></a>2、包裹式方法</h2><ul>
<li><p>​     递归特征消除法</p>
<p>递归消除特征法使用一个基模型来进行多轮训练，每轮训练后，消除若干权值系数的特征，再基于新的特征集进行下一轮训练。</p>
</li>
</ul>
<h2 id="3、Embedded方法"><a href="#3、Embedded方法" class="headerlink" title="3、Embedded方法"></a>3、Embedded方法</h2><ul>
<li>基于惩罚项的特征选择法</li>
<li>基于树模型的特征选择法</li>
</ul>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/03/21/机器学习笔记/" title="" itemprop="url"></a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="PengYuan" target="_blank" itemprop="author">PengYuan</a>
		
  <p class="article-time">
    <time datetime="2018-03-21T07:34:13.465Z" itemprop="datePublished"> 发表于 2018-03-21</time>
    
  </p>
</header>
    <div class="article-content">
        
        <hr>
<h2 id="title-机器学习笔记"><a href="#title-机器学习笔记" class="headerlink" title="title:机器学习笔记"></a>title:机器学习笔记</h2><h3 id="机器学习的数据不平衡解决方法"><a href="#机器学习的数据不平衡解决方法" class="headerlink" title="机器学习的数据不平衡解决方法"></a>机器学习的数据不平衡解决方法</h3><p>理解：简单理解就是训练样本的得到的输出和期望输出基本一致，但是样本输出和测试样本的期望输出相差却很大 ，为了得到一致假设而使假设变得过度复杂称为过拟合。</p>
<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>数据不平衡指的是分类任务中不同类别的训练数据样本数目差别很大，失去一般性。如，一个样本中正例998个，负例2个，就会导致无论什么模型结果的准确率都会很高，现实生活中，样本应该平均分布。</p>
<h4 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h4><h5 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h5><p>上采样：上采样是把小众类复制多份</p>
<p>缺点：造成过拟合现象发生</p>
<p>下采样：下采样是从大众类中剔除一些样本，或者说只从大众类中选取部分样本</p>
<p>缺点：模拟数据量小，学习到总体模型的一部分。</p>
<h5 id="加权"><a href="#加权" class="headerlink" title="加权"></a>加权</h5><p>通过加权的方式来解决数据不平衡问题，即对不同类别分错的代价不同，如下图：</p>
<table>
<thead>
<tr>
<th></th>
<th>1</th>
<th>2</th>
<th>…</th>
<th>k</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0</td>
<td>C(1,2)</td>
<td>…</td>
<td>C(1,k)</td>
</tr>
<tr>
<td>2</td>
<td>C(2,1)</td>
<td>0</td>
<td>…</td>
<td>…</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
<tr>
<td>k</td>
<td>C(k,1)</td>
<td>C(k,2)</td>
<td>…</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>横向是真实分类情况，纵向是预测分类情况，C(i,j)是把真实类别为j的样本预测为i时的损失，我们需要根据实际情况来设定它的值。</p>
<h5 id="转化为一分类问题"><a href="#转化为一分类问题" class="headerlink" title="转化为一分类问题"></a>转化为一分类问题</h5><p>对于二分类问题，如果正负样本分布比例极不平衡，我们可以换一个完全不同的角度来看待问题：把它看做一分类（One Class Learning）或异常检测（Novelty Detection）问题。这类方法的重点不在于捕捉类间的差别，而是为其中一类进行建模。</p>
<h3 id="多分类学习"><a href="#多分类学习" class="headerlink" title="多分类学习"></a>多分类学习</h3><p>理解：在现实生活中经常遇到多分类问题，而学习的分类模型大多为二分类模型，如LR，SVM。接下来基于策略，利用二分类解决多分类问题。</p>
<p>策略：”拆解法”，将多分类问题拆分为多个二分类任务求解。</p>
<p>经典的拆分策略分为：</p>
<h5 id="一对一（one-vs-one）"><a href="#一对一（one-vs-one）" class="headerlink" title="一对一（one vs one）"></a>一对一（one vs one）</h5><p>将N个类别两两配对，产生，即N（N-1）/2个分类结果，最终结果通过投票产生，投票是把被预测的最多的类别作为最终分类结果。</p>
<h5 id="一对其余（one-vs-rest）"><a href="#一对其余（one-vs-rest）" class="headerlink" title="一对其余（one vs rest）"></a>一对其余（one vs rest）</h5><p>每次将一个类的样例作为正样本，其他的作为负样本，训练N个分类器。选择预测置信度最大的标记类别作为分类结果。以上两种策略如图所示.</p>
<p><img src="http://120.25.221.136/images/duofenlei.png" alt=""></p>
<h5 id="多对多（Many-vs-Many）"><a href="#多对多（Many-vs-Many）" class="headerlink" title="多对多（Many vs Many）"></a>多对多（Many vs Many）</h5><p>每次将若干个类作为正样本，若干个类作为负样本，，MvM的正负样本设计必须有特殊的设计，最常用的是ECOC（Error Correcting Output Codes）分为编码阶段与解码阶段。</p>
<p>编码阶段：对N个类别进行M次划分，每次将一部分类划分为正类，一部分类划分为反类，编码矩阵有两种形式：二元码和三元码，前者只有正类和反类，后者除了正类和和反类还有停用类，在解码阶段，各分类器的预测结果联合起来形成测试示例的编码，该编码与各类所对应的编码进行比较，将距离最小的编码所对应的类别作为预测结果。</p>
<p><img src="http://120.25.221.136/images/ecos.png" alt=""></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/03/19/sql的casewhen语句/" title="sql的casewhen语句" itemprop="url">sql的casewhen语句</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="PengYuan" target="_blank" itemprop="author">PengYuan</a>
		
  <p class="article-time">
    <time datetime="2018-03-19T11:12:37.960Z" itemprop="datePublished"> 发表于 2018-03-19</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>背景：面试阿里时面试官给了sql语句的题目，结果回答不出来，连听都没听过，尴尬。问了才知道使用case when 语句。</p>
<h4 id="行转列"><a href="#行转列" class="headerlink" title="行转列"></a>行转列</h4><h5 id="利用max-case-when-then"><a href="#利用max-case-when-then" class="headerlink" title="利用max(case when  then)"></a>利用max(case when  then)</h5><ul>
<li>建一张成绩表，要求将所有门成绩转为一行，不同学科作为不同的属性列。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#建表sql</span><br><span class="line">create table score    </span><br><span class="line">(       </span><br><span class="line">   name varchar(30) null,    </span><br><span class="line">   coursename varchar(10) null,    </span><br><span class="line">   score int null   </span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#插入数据</span><br><span class="line">insert into score values (&apos;张三&apos;,&apos;语文&apos;,80);   </span><br><span class="line">insert into score values (&apos;张三&apos;,&apos;数学&apos;,98);    </span><br><span class="line">insert into score values (&apos;张三&apos;,&apos;英语&apos;,65);    </span><br><span class="line">insert into score values (&apos;李四&apos;,&apos;语文&apos;,70);    </span><br><span class="line">insert into score values (&apos;李四&apos;,&apos;数学&apos;,80);    </span><br><span class="line">insert into score values (&apos;李四&apos;,&apos;英语&apos;,90);</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#case when sql</span><br><span class="line">select</span><br><span class="line">    name as &apos;姓名&apos; ,     </span><br><span class="line">    max(case coursename when &apos;语文&apos; then score else 0 end) &apos;语文&apos;,     </span><br><span class="line">    max(case coursename when &apos;数学&apos; then score else 0 end) &apos;数学&apos;,     </span><br><span class="line">    max(case coursename when &apos;英语&apos; then score else 0 end) &apos;英语&apos;     </span><br><span class="line">from score     </span><br><span class="line">group by name</span><br></pre></td></tr></table></figure>
<p>运行结果投如下图所示</p>
<p><img src="http://120.25.221.136/images/casewhen.png" alt=""></p>
<ul>
<li><p>将课程分类</p>
<p>​</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#case when sql</span><br><span class="line"></span><br><span class="line">select </span><br><span class="line">      name as &apos;姓名&apos;,</span><br><span class="line">      case</span><br><span class="line">          when coursename=&apos;数学&apos; then &apos;理科&apos;</span><br><span class="line">          else &apos;文科&apos;</span><br><span class="line">      end as &apos;科别&apos;,</span><br><span class="line">      sum(score) as &apos;总分&apos;</span><br><span class="line">from score</span><br><span class="line">group by </span><br><span class="line">      name,</span><br><span class="line">      case</span><br><span class="line">          when coursename=&apos;数学&apos; then &apos;理科&apos;</span><br><span class="line">          else &apos;文科&apos;</span><br><span class="line">      end</span><br></pre></td></tr></table></figure>
<p><img src="http://120.25.221.136/images/case2.png" alt=""></p>
</li>
</ul>
<h5 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h5><p>case when具有两种形式：</p>
<ol>
<li><p>简单case函数</p>
<p>CASE sex </p>
<pre><code>WHEN &apos;1&apos; THEN &apos;男&apos; 
WHEN &apos;2&apos; THEN &apos;女&apos; 
</code></pre><p>ELSE ‘其他’ END </p>
<p>2.case搜索函数</p>
<p>CASE WHEN sex = ‘1’ THEN ‘男’ </p>
<pre><code>WHEN sex = &apos;2&apos; THEN &apos;女&apos; 
</code></pre><p>ELSE ‘其他’ END </p>
</li>
</ol>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/03/14/运行pyspark遇到的问题/" title="运行pyspark遇到的问题" itemprop="url">运行pyspark遇到的问题</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="PengYuan" target="_blank" itemprop="author">PengYuan</a>
		
  <p class="article-time">
    <time datetime="2018-03-14T08:54:38.033Z" itemprop="datePublished"> 发表于 2018-03-14</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>环境：spark-2.3.0-bin-hadoop2.7,python3.6</p>
<p>问题：Unable to load native-hadoop library for your platform… using builtin-java classes where applicable<br>Stopping namenodes …</p>
<p>解决方法：是因为不能加载本地库，在Java的$JAVA_HOME/jre/lib/amd64目录下缺少libhadoop.so和libsnappy.so文件。</p>
<p>libhadoop.so可以在Hadoop目录下的Hadoop\lib\native找到，将它放入上述jre目录下。</p>
<p><img src="http://120.25.221.136/images/libhadoop.png" alt=""></p>
<p>可以从<a href="https://code.google.com/p/snappy/下载源码，通过编译源码安装，" target="_blank" rel="noopener">https://code.google.com/p/snappy/下载源码，通过编译源码安装，</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf snappy-1.1.1.tar.gz</span><br><span class="line"></span><br><span class="line">cd snappy-1.1.1</span><br><span class="line"></span><br><span class="line">./configure</span><br><span class="line"></span><br><span class="line">make</span><br><span class="line"></span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>
<p>安装完成之后，在usr/local/lib目录下找到libsnappy.so，放入jre目录下。重启spark就可以解决问题。</p>
<p><img src="http://120.25.221.136/images/libsnappy.png" alt=""></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/03/03/机器学习的过拟合解决方法/" title="机器学习的过拟合解决方法" itemprop="url">机器学习的过拟合解决方法</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="PengYuan" target="_blank" itemprop="author">PengYuan</a>
		
  <p class="article-time">
    <time datetime="2018-03-03T12:38:06.757Z" itemprop="datePublished"> 发表于 2018-03-03</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>定义：简单理解就是训练样本的得到的输出和期望输出基本一致，但是样本输出和测试样本的期望输出相差却很大 ，为了得到一致假设而使假设变得过度复杂称为过拟合，如图：</p>
<p><img src="http://120.25.221.136/images/overfitting.png" alt=""></p>
<h3 id="解决方法："><a href="#解决方法：" class="headerlink" title="解决方法："></a>解决方法：</h3><h4 id="1-增加数据量"><a href="#1-增加数据量" class="headerlink" title="1. 增加数据量"></a>1. 增加数据量</h4><p>数据量增加会将模型适应更多的数据集，对测试集验证的更加准确。</p>
<h4 id="2-正则化"><a href="#2-正则化" class="headerlink" title="2.正则化"></a>2.正则化</h4><p>拟合发生时，往往会出现拟合函数在训练数据点上的“曲率”很大。而这些“曲率”是由模型的参数近似表达出来的，因此通过对大值参数的惩罚来抑制这种曲率的发生。</p>
<p><strong>正则化的作用：</strong></p>
<ul>
<li>L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择</li>
<li>L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合</li>
</ul>
<p><strong>L1正则化和L2正则化的说明如下：</strong></p>
<ul>
<li>L1正则化是指权值向量w中各个元素的<strong>绝对值之和</strong>，通常表示为||w||1</li>
<li>L2正则化是指权值向量w中各个元素的<strong>平方和然后再求平方根</strong>（可以看到Ridge回归的L2正则化项有平方符号），通常表示为||w||2</li>
</ul>
<h4 id="3-Dropout"><a href="#3-Dropout" class="headerlink" title="3.Dropout"></a>3.Dropout</h4><p>在一次循环中我们先随机选择神经层中的一些单元并将其临时隐藏，然后再进行该次循环中神经网络的训练和优化过程。在下一次循环中，我们又将隐藏另外一些神经元，如此直至训练结束。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/03/02/学习tensorflow/" title="学习tensorflow" itemprop="url">学习tensorflow</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="PengYuan" target="_blank" itemprop="author">PengYuan</a>
		
  <p class="article-time">
    <time datetime="2018-03-02T13:46:04.615Z" itemprop="datePublished"> 发表于 2018-03-02</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>环境：环境为Windows7，64位，python 3.6</p>
<h4 id="pip安装"><a href="#pip安装" class="headerlink" title="pip安装"></a><strong>pip安装</strong></h4><p>因为之前已经装好python和pip只需要输入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># CPU 版的</span><br><span class="line">C:\&gt; pip3 install --upgrade tensorflow</span><br></pre></td></tr></table></figure>
<p>装好之后测试是否安装成功。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow</span><br></pre></td></tr></table></figure>
<p><img src="http://120.25.221.136/images/tensorsucess.png" alt=""></p>
<p>运行遇到问题：Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2</p>
<p>解决方法：没有支持cuda的gpu，通过加上警告级别，忽视警告。</p>
<p>在python文件加入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">os.environ[&apos;TF_CPP_MIN_LOG_LEVEL&apos;] = &apos;2&apos;</span><br></pre></td></tr></table></figure>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/02/02/剑指Offer编程题Python编写/" title="剑指Offer编程集合" itemprop="url">剑指Offer编程集合</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="PengYuan" target="_blank" itemprop="author">PengYuan</a>
		
  <p class="article-time">
    <time datetime="2018-02-02T08:32:35.488Z" itemprop="datePublished"> 发表于 2018-02-02</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>注意：所有题目使用Python语言实现</p>
<h4 id="一、用两个栈实现队列"><a href="#一、用两个栈实现队列" class="headerlink" title="一、用两个栈实现队列"></a>一、<a href="https://www.nowcoder.com/practice/54275ddae22f475981afa2244dd448c6?tpId=13&amp;tqId=11158&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">用两个栈实现队列</a></h4><p>题目描述：用两个栈来实现一个队列，完成队列的Push和Pop操作。 队列中的元素为int类型。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line">class Solution:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.stack1 = [] #定义两个空数组</span><br><span class="line">        self.stack2 = []</span><br><span class="line">    def push(self, node):</span><br><span class="line">        self.stack1.append(node)#往数组中加入数据</span><br><span class="line">    def pop(self):</span><br><span class="line">        if self.stack1 == []:#判断栈1是否为空，若为空说明为空栈</span><br><span class="line">            return None</span><br><span class="line">        else:#否则利用两个数组实现先进先出</span><br><span class="line">            for i in range(0, len(self.stack1)):</span><br><span class="line">                self.stack2.append(self.stack1.pop())</span><br><span class="line">            res = self.stack2.pop()</span><br><span class="line">            while self.stack2:</span><br><span class="line">                self.stack1.append(self.stack2.pop())</span><br><span class="line">            return res</span><br></pre></td></tr></table></figure>
<h4 id="二、斐波那契数列"><a href="#二、斐波那契数列" class="headerlink" title="二、斐波那契数列"></a>二、<a href="https://www.nowcoder.net/practice/c6c7742f5ba7442aada113136ddea0c3?tpId=13&amp;tqId=11160&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">斐波那契数列</a></h4><p>题目描述：大家都知道斐波那契数列，现在要求输入一个整数n，请你输出斐波那契数列的第n项。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line">class Solution:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.res=0</span><br><span class="line">        self.a=0</span><br><span class="line">        self.b=1</span><br><span class="line">    def Fibonacci(self, n):</span><br><span class="line">        if n&gt;1:</span><br><span class="line">            for i in range(2,n+1):</span><br><span class="line">                self.res=self.a+self.b</span><br><span class="line">                temp=self.b</span><br><span class="line">                self.b=self.res</span><br><span class="line">                self.a=temp</span><br><span class="line">        elif n==1:</span><br><span class="line">            return 1</span><br><span class="line">        elif n==0:</span><br><span class="line">            return 0</span><br><span class="line">        return self.res</span><br></pre></td></tr></table></figure>
<h4 id="三、数值的整数次方"><a href="#三、数值的整数次方" class="headerlink" title="三、数值的整数次方"></a>三、<a href="https://www.nowcoder.net/practice/1a834e5e3e1a4b7ba251417554e07c00?tpId=13&amp;tqId=11165&amp;tPage=1&amp;rp=1&amp;ru=/ta/coding-interviews&amp;qru=/ta/coding-interviews/question-ranking" target="_blank" rel="noopener">数值的整数次方</a></h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line">class Solution:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.res=1</span><br><span class="line">    def Power(self, base, exponent):</span><br><span class="line">        if exponent&gt;=0:</span><br><span class="line">            for i in range(1,exponent+1):</span><br><span class="line">                self.res=self.res*base</span><br><span class="line">        else:</span><br><span class="line">            for i in range(1,abs(exponent)+1):</span><br><span class="line">                self.res=self.res*(1/base)</span><br><span class="line">        return self.res</span><br><span class="line">注意：指数分为正整数与负整数，考虑不同情况。</span><br></pre></td></tr></table></figure>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/29/hadoop安装hive/" title="Hadoop安装hive详细过程" itemprop="url">Hadoop安装hive详细过程</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="PengYuan" target="_blank" itemprop="author">PengYuan</a>
		
  <p class="article-time">
    <time datetime="2018-01-29T08:16:46.707Z" itemprop="datePublished"> 发表于 2018-01-29</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>环境：主节点和两个从节点都为腾讯云CentOS 7.0 64位<br>Hadoop版本为hadoop-2.8.0。</p>
<p>说明：安装hive前提是要先安装hadoop集群，并且hive只需要再hadoop的namenode节点集群里安装即可(需要再所有namenode上安装)，可以不在datanode节点的机器上安装，在本文中有Hadoop的命令的前提是Hadoop是已经运行着。</p>
<h4 id="一、下载hive"><a href="#一、下载hive" class="headerlink" title="一、下载hive"></a>一、下载hive</h4><p>1.下载<a href="http://mirrors.shu.edu.cn/apache/hive/hive-2.3.2/" target="_blank" rel="noopener">hive-2.3.2</a>放入主服务器中建立hive文件夹，并执行tar -zvxf apache-hive-2.3.2-bin.tar.gz解压。<img src="http://120.25.221.136/images/hivemirror.png" alt=""></p>
<p><img src="http://120.25.221.136/images/hivepack.png" alt=""></p>
<p>2.配置环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line">#在profile文件中增加下列配置，每个人安装路径不一样，要灵活变化</span><br><span class="line">#set hive environment</span><br><span class="line">export HIVE_HOME=/usr/local/hadoop/hive/apache-hive-2.3.2-bin</span><br><span class="line">export PATH=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure>
<p>3.在hive的安装路径下，/usr/local/hadoop/hive/apache-hive-2.3.2-bin/conf找到 hive-default.xml.template改名为hive-site.xml。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp   hive-default.xml.template   hive-site.xml</span><br></pre></td></tr></table></figure>
<p>因为在 hive-site.xml的配置中有。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/user/hive/warehouse&lt;/value&gt;</span><br><span class="line">   &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;/tmp/hive&lt;/value&gt;</span><br></pre></td></tr></table></figure>
<p>所有需要Hadoop的HDFS中建立文件夹。</p>
<p>在Hadoop的安装目录中，执行。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">bin/hadoop   fs   -mkdir   -p   /user/hive/warehouse</span><br><span class="line">bin/hadoop   fs   -chmod   777   /user/hive/warehouse</span><br><span class="line">bin/hadoop   fs   -mkdir  -p   /tmp/hive/</span><br><span class="line">bin/hadoop   fs   -chmod  777   /tmp/hive</span><br><span class="line">bin/hadoop   fs   -ls   /user/hive/</span><br></pre></td></tr></table></figure>
<p>在浏览器中可以查看到建立的文件，如图。</p>
<p><img src="http://120.25.221.136/images/webbo.png" alt=""></p>
<p><img src="http://120.25.221.136/images/file.png" alt=""></p>
<p>4.修改配置文件hive-site.xml， 将hive-site.xml文件中的{system:java.io.tmpdir}替换为hive的临时目录，例如我替换为/opt/hive/tmp，将{system:user.name}都替换为root，注意，需要将配置文件中所有的都替换掉，更改后的一张截图。</p>
<p><img src="http://120.25.221.136/images/change.png" alt=""></p>
<p>5.增加下列配置到hive-site.xml中，其中的数据库为你想要连接的数据库的ip.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; </span><br><span class="line">    &lt;value&gt;jdbc:mysql://ip:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;username to use against metastore database&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;2012213405&lt;/value&gt;</span><br><span class="line">    &lt;description&gt;password to use against metastore database&lt;/description&gt;</span><br><span class="line">  &lt;/property&gt;</span><br></pre></td></tr></table></figure>
<p>6.在hive的安装路径下，/usr/local/hadoop/hive/apache-hive-2.3.2-bin/conf找到 hive-env.sh.template改名为hive-env.sh。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp    hive-env.sh.template    hive-env.sh</span><br></pre></td></tr></table></figure>
<p>在内容中去掉三个环境设置，增加自己的安装环境变量。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># Set HADOOP_HOME to point to a specific hadoop install directory</span><br><span class="line"> HADOOP_HOME=/usr/local/hadoop/hadoop-2.8.0</span><br><span class="line"></span><br><span class="line"># Hive Configuration Directory can be controlled by:</span><br><span class="line"> export HIVE_CONF_DIR=/usr/local/hadoop/hive/apache-hive-2.3.2-bin/conf</span><br><span class="line"></span><br><span class="line"># Folder containing extra libraries required for hive compilation/execution can be controlled by:</span><br><span class="line"> export HIVE_AUX_JARS_PATH=/usr/local/hadoop/hive/apache-hive-2.3.2-bin/lib</span><br></pre></td></tr></table></figure>
<h4 id="二、下载mysql-connector-java"><a href="#二、下载mysql-connector-java" class="headerlink" title="二、下载mysql-connector-java"></a>二、下载<a href="https://dev.mysql.com/downloads/connector/j/5.0.html" target="_blank" rel="noopener">mysql-connector-java</a></h4><p>连接MySQL，作为默认的元数据库，下载完成之后，在主服务器中建立文件夹mysql-connector，上传文件，并解压。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#tar -zxvf mysql-connector-java-5.1.45.tar.gz</span><br></pre></td></tr></table></figure>
<p><img src="http://120.25.221.136/images/mysqlconn.png" alt=""></p>
<p><img src="http://120.25.221.136/images/mysqlco.png" alt=""></p>
<p>将解压后的mysql-connector-java-5.1.45-bin.jar，放入到hive的lib文件下，我的是/usr/local/hadoop/hive/apache-hive-2.3.2-bin/lib。</p>
<p><img src="http://120.25.221.136/images/mysqlbin.png" alt=""></p>
<p><img src="http://120.25.221.136/images/changeconn.png" alt=""></p>
<h4 id="三、启动和测试"><a href="#三、启动和测试" class="headerlink" title="三、启动和测试"></a>三、启动和测试</h4><p>在hive的安装的bin路径下在，执行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#schematool -initSchema -dbType mysql</span><br></pre></td></tr></table></figure>
<p><img src="http://120.25.221.136/images/startest.png" alt=""></p>
<p>在连接的MySQL中创建了hive数据库和多张表。</p>
<p><img src="http://120.25.221.136/images/table.png" alt=""></p>
<p>在bin路径下执行启动hive的命令。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#./hive</span><br></pre></td></tr></table></figure>
<p><img src="http://120.25.221.136/images/starthive.png" alt=""></p>
<p>在hive环境下，执行hql语句，与sql语句很相像。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">show databases;</span><br><span class="line">create database db_hive_edu;</span><br><span class="line">use database db_hive_edu;</span><br><span class="line">create  table  student(id int,name string)  row  format  delimited  fields   terminated  by  &apos;\t&apos;;</span><br></pre></td></tr></table></figure>
<p>创建student.txt,里面是id和name的内容，之间用tab键隔开。</p>
<p><img src="http://120.25.221.136/images/datatab.png" alt=""></p>
<p><img src="http://120.25.221.136/images/hsql.png" alt=""></p>
<p><img src="http://120.25.221.136/images/insert.png" alt=""></p>
<p><img src="http://120.25.221.136/images/load.png" alt=""></p>
<p>用MySQL查询可以查询到建立的student表。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT  * FROM  hive.TBLS</span><br></pre></td></tr></table></figure>
<p><img src="http://120.25.221.136/images/tablename.png" alt=""></p>
<p>遇到问题：启动hive的时候报错。</p>
<p><img src="http://120.25.221.136/images/error1.png" alt=""></p>
<p><img src="http://120.25.221.136/images/error2.png" alt=""></p>
<p>解决方法：是因为namenode节点没有运行，需要重新启动Hadoop即可。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#sbin/start-all.sh</span><br></pre></td></tr></table></figure>
<h4 id="Mysql作为Hive的metastore原因："><a href="#Mysql作为Hive的metastore原因：" class="headerlink" title="Mysql作为Hive的metastore原因："></a><strong>Mysql作为Hive的metastore原因：</strong></h4><p>hive 默认使用 derby 作为映射表（SQL 操作映射为MapReduce Job，将SQL中创建的表映射为 hdfs 的文件/文件夹，字段映射为其中的行），但 derby 的一大缺陷在于它不允许多个客户端同时执行sql操作还可存放于 mysql 中来访问Hive。</p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/28/搭建saprk集群/" title="搭建saprk集群" itemprop="url">搭建saprk集群</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="PengYuan" target="_blank" itemprop="author">PengYuan</a>
		
  <p class="article-time">
    <time datetime="2018-01-28T07:46:54.036Z" itemprop="datePublished"> 发表于 2018-01-28</time>
    
  </p>
</header>
    <div class="article-content">
        
        <p>环境：主节点和两个从节点都为腾讯云CentOS 7.0 64位</p>
<p>Hadoop版本为hadoop-2.8.0</p>
<h4 id="一、安装scala"><a href="#一、安装scala" class="headerlink" title="一、安装scala"></a>一、安装scala</h4><p>1.下载<a href="https://downloads.lightbend.com/scala/2.11.8/scala-2.11.8.tgz" target="_blank" rel="noopener">scala-2.11.8.tgz</a>，将它放入主服务器中，建立文件夹，存放路径为/usr/local/hadoop/scala</p>
<p><img src="../img/1.png" alt=""></p>
<p>2.解压scala文件，执行tar -zvxf scala-2.11.8.tgz。</p>
<p>3.配置scala环境变量。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim  /etc/profile</span><br><span class="line">增加scala环境路径，根据你的放置文件路径。</span><br><span class="line">#set scala environment</span><br><span class="line">export SCALA_HOME=/usr/local/hadoop/scala/scala-2.11.8</span><br><span class="line">export PATH=$PATH:$SCALA_HOME/bin</span><br><span class="line"># source /etc/profile #重新激活环境变量</span><br></pre></td></tr></table></figure>
<p>4.在你的子结点重复上面的步骤，安装scala在子结点中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scp -r /usr/local/hadoop/scala/scala-2.11.8  slaver1:/usr/local/hadoop/scala</span><br><span class="line">scp -r /usr/local/hadoop/scala/scala-2.11.8  slaver2:/usr/local/hadoop/scala</span><br></pre></td></tr></table></figure>
<p>注意：也可以通过别的工具上传再解压，加快速度。</p>
<p>5.测试安装是否成功，输入scala进入scala编辑环境。</p>
<p><img src="../img/2.png" alt=""></p>
<h4 id="二、安装spark"><a href="#二、安装spark" class="headerlink" title="二、安装spark"></a>二、安装spark</h4><p>1.下载<a href="http://www.apache.org/dist/spark/spark-2.2.0/" target="_blank" rel="noopener">spark</a>,在主服务器中上传压缩包并解压，存放路径为/usr/local/hadoop/spark</p>
<p>2.解压scala文件，执行tar -zvxf spark-2.2.0-bin-hadoop2.7.tgz。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># tar -zvxf spark-2.2.0-bin-hadoop2.7.tgz</span><br></pre></td></tr></table></figure>
<p>3.在spark目录下的配置文件中，找到spark-env.sh.template文件复制为另一文件改名为spark-env.sh。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp spark-env.sh.template   spark-env.sh</span><br></pre></td></tr></table></figure>
<p>4.配置spark-env.sh文件。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">export HADOOP_CONF_DIR=/usr/local/hadoop/hadoop-2.8.0/#hadoop配置文件路径</span><br><span class="line">export JAVA_HOME=/usr/local/hadoop/java/jdk1.8.0_151/#jdk环境变量</span><br><span class="line">export SCALA_HOME=/usr/local/hadoop/scala/scala-2.11.8#scala环境变量</span><br><span class="line">export SPARK_MASTER_IP=你的主服务器内网ip</span><br><span class="line">export SPARK_MASTER_PORT=7077#master启动的端口号</span><br><span class="line">export SPARK_MASTER_WEBUI_PORT=8080#webui的端口号</span><br><span class="line">export SPARK_WORKER_PORT=7078#worker的启动端口号</span><br><span class="line">export SPARK_WORKER_WEBUI_PORT=worker的webUI端口号</span><br><span class="line">export SPARK_WORKER_CORES=1#作业可用的CPU内核数量（默认：所有可用</span><br><span class="line">export SPARK_WORKER_INSTANCES=1</span><br><span class="line">export SPARK_WORKER_MEMORY=2g#作业可使用的内存容量</span><br></pre></td></tr></table></figure>
<p>5.配置spark-defaults.conf,找到spark-defaults.conf.template文件复制为另一文件改名为spark-defaults.conf.template。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp spark-defaults.conf.template   spark-defaults.conf</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">	</span><br><span class="line">#该参数需要根据用户master节点的实际ip地址进行配置</span><br><span class="line">spark.master=spark://主服务器内网ip:7077</span><br></pre></td></tr></table></figure>
<p>6.配置slaves,找到slaves.template文件复制为另一文件改名为slaves。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp slaves.template slaves</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#增加从节点</span><br><span class="line">slaver1</span><br><span class="line">slaver2</span><br></pre></td></tr></table></figure>
<p><img src="../img/3.png" alt=""></p>
<p>7.配置环境变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#vim  /etc/profile</span><br><span class="line"></span><br><span class="line">#set spark environment</span><br><span class="line">export SPARK_HOME=/usr/local/hadoop/spark/spark-2.2.0-bin-hadoop2.7</span><br><span class="line">export PATH=$PATH:$SPARK_HOME/bin</span><br><span class="line"></span><br><span class="line">#source /etc/profile</span><br></pre></td></tr></table></figure>
<p>8.在从节点里重复上述步骤。</p>
<p>9.启动spark（Hadoop是已经启动的），运行下列命令。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#开启</span><br><span class="line">sbin/start-all.sh</span><br><span class="line">或者</span><br><span class="line">sbin/start-master.sh</span><br><span class="line">sbin/start-slaves.sh</span><br><span class="line">#停止</span><br><span class="line">sbin/stop-all.sh</span><br><span class="line">或者</span><br><span class="line">sbin/stop-master.sh</span><br><span class="line">sbin/stop-slaves.sh</span><br></pre></td></tr></table></figure>
<p><img src="../img/4.png" alt=""></p>
<p>10.查看执行状态，输入命令jps，可以看到相关信息</p>
<p>主节点</p>
<p><img src="../img/5.png" alt=""></p>
<p>从节点</p>
<p><img src="../img/6.png" alt=""></p>
<p>在浏览器中，查看spark集群状态 ，master节点输入网址<a href="http://master:8080/" target="_blank" rel="noopener">http://masterip:8080</a> </p>
<p><img src="../img/7.png" alt=""></p>

        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>






   
    
    <article class="post-expand post" itemprop="articleBody"> 
        <header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/01/27/Hexo绑定域名/" title="Hexo绑定域名" itemprop="url">Hexo绑定域名</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="PengYuan" target="_blank" itemprop="author">PengYuan</a>
		
  <p class="article-time">
    <time datetime="2018-01-27T09:09:15.496Z" itemprop="datePublished"> 发表于 2018-01-27</time>
    
  </p>
</header>
    <div class="article-content">
        
        <h4 id="一、购买域名"><a href="#一、购买域名" class="headerlink" title="一、购买域名"></a>一、购买域名</h4><p>可以在阿里云或者腾讯云购买域名，我的在腾讯云购买，域名为[pengyuan.ac.cn</p>
<h4 id="二、解析域名"><a href="#二、解析域名" class="headerlink" title="二、解析域名"></a>二、解析域名</h4><p>登入腾讯云控制台，如图，找到域名管理，对你绑定的域名进行解析。</p>
<p><img src="http://120.25.221.136/images/console.png" alt=""></p>
<h4 id="三、添加解析记录"><a href="#三、添加解析记录" class="headerlink" title="三、添加解析记录"></a>三、添加解析记录</h4><p>点击添加解析，记录类型选A或CNAME，A记录的记录值就是ip地址，github(官方文档)提供了两个IP地址，<code>192.30.252.153和192.30.252.154</code>，这两个IP地址为github的服务器地址，两个都要解析。解析记录设置两个www和@，线路就默认就行，CNAME记录值填你的github博客网址。</p>
<p><img src="http://120.25.221.136/images/jiexi.png" alt=""></p>
<p><img src="http://120.25.221.136/images/git.png" alt=""></p>
<h4 id="四、增加CNAME文件"><a href="#四、增加CNAME文件" class="headerlink" title="四、增加CNAME文件"></a>四、增加CNAME文件</h4><p>在Hexo的目录下的source文件夹下增加cname文件，文件的内容是你的域名我的是<a href="pengyuan.ac.cn">pengyuan.ac.cn</a></p>
<p><img src="http://120.25.221.136/images/cname.png" alt=""></p>
<p><img src="http://120.25.221.136/images/content.png" alt=""></p>
<h4 id="最后访问域名，就可以访问成功。"><a href="#最后访问域名，就可以访问成功。" class="headerlink" title="最后访问域名，就可以访问成功。"></a>最后访问域名，就可以访问成功。</h4>
        
        
        <p class="article-more-link">
          
       </p>
    </div>
    <footer class="article-footer clearfix">
<div class="article-catetags">


</div>




<div class="comments-count">
	
</div>

</footer>


    </article>







  <nav id="page-nav" class="clearfix">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next<span></span></a>
  </nav>

</div>
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  
<div class="github-card">
<p class="asidetitle">Github 名片</p>
<div class="github-card" data-github="https://github.com/pengyuanqiuqiu" data-theme="medium"></div>
<script type="text/javascript" src="//cdn.jsdelivr.net/github-cards/latest/widget.js" ></script>
</div>



  

  

  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://coderq.com" target="_blank" title="一个面向程序员交流分享的新一代社区">码农圈</a>
            
          </li>
        
          <li>
            
            	<a href="https://www.nowcoder.com/" target="_blank" title="牛客网">牛客网</a>
            
          </li>
        
          <li>
            
            	<a href="http://www.acmcoder.com/index" target="_blank" title="赛码网">赛码网</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="http://www.163.com/rss/" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="400" class="share_self"  frameborder="0" scrolling="no" src="https://widget.weibo.com/weiboshow/index.php?language=&width=0&height=400&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=1&isFans=0&uid=2871001534&verifier=2889e96f&colors=d6f3f7,ffffff,666666,0082cb,ecfbfd&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m jianyu. <br/>
			Let&#39;s go!</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/2871001534" target="_blank" class="icon-weibo" title="微博"></a>
		
		
		<a href="https://github.com/pengyuanqiuqiu" target="_blank" class="icon-github" title="github"></a>
		
		
		
		
		
		
		
		<a href="http://www.zhihu.com/people/peng-yuan-19-57?utm_source=qq&amp;utm_medium=social" target="_blank" class="icon-zhihu" title="知乎"></a>
		
		
		
		<a href="mailto:987219258@qq.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by © 2018 
		
		<a href="https://pengyuanqiuqiu.github.io/" target="_blank" title="PengYuan">PengYuan</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
        
    }
  });
});
</script>












<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
 </html>
